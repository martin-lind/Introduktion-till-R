---
title: "Icke-parametriska tester"
---

De statistiska test vi behandlat nu är parametriska test, dvs de förutsätter att datan eller residualerna följer vissa fördelningar (exempelvis normalfördelning). Simuleringar visar också att parametriska modeller är väldigt robusta även mot avvikelser i normalförderade residualer (se exempelvis [Knief & Forstmeier 2021](https://link.springer.com/article/10.3758/s13428-021-01587-5)). Om residualerna dessutom avviker från normalfördelning kan det i många fall lösas genom transformeringar (se tidigare tutoriel) elelr genom att använda generaliserade linjära modeller som kan specificera en annan errorstruktur.

Ibland har man dock väldigt "konstiga" data, och speciellt om de samtidigt kommer från små dataset så kan man ibland behöva överväga icke-parametriska metoder.

Icke-parametriska metoder bygger på att värderna rankas, dvs är ett visst värde generellt högre eller lägre än de andra värderna. Testen använder sig inte av de exakta mätvärderna och tappar därmed mycket information (de är svaga test). Testen har svårare att upptäcka mönster som faktiskt finns och skall därmed bara användas i nödfall.

***Man kan överväga ickeparametriska metoder om:***

-   Responsvariabeln är på *ordinalskala* (till exempel att arters täthet är skattad som ovanlig, vanlig, mycket vanlig), kategorierna är därmed ordnade men går inte att översätta till mätvärden

-   Responsvariabeln innehåller väldigt många nollvärden

-   Datasetet innehåller några kraftigt avvikande värden (*outliers*) som du litar på och behöver inkludera i datasetet

-   Datasetet är litet och residualerna är långt ifrån normalfördelade

Icke-parametriska test skall ses som ett svagt test som används som en nödlösning i små och avvikande dataset. Data som uppfyller många av punkterna ovan kan analyseras med parametriska test om datasetet är stort nog.

## Icke-paramatriska test

De icke-parametriska testen som oftast används är:

-   **Wilcoxons test**: ersätter t-test

-   **Kruskal-Wallis test**: ersätter envägs-anova

-   **Spearman korrelation**: ersätter Pearson-korrelation

## Wilcoxons test

Wilcoxons test (kallas ibland Mann-Whitney U-test) används som ett icke-parametriskt alternativ till t-test

Vi vill undersöka om den sydliga kärrsnäppans häckningsframgång kan förbättras om man har predatorkontroll. Vi har därför inventerat antalet ungar hos honor i slumpvis utvalda bon i områden där man haft predatorkontroll, och områden där inga åtgärder gjorts.

### Läs in data
Ladda ner följande fil [dunlin.txt](data/dunlin.txt) (högerklicka, välj "spara länk som") och spara filen på din hårddisk i en mapp med ett lämpligt namn.

Fortsätt med att läsa in datasetet och ge det ett namn, i det här fallet kallar vi det `dunlin_data.` En detalerad beskrivning i hur man läser in filer finns i vår tidigare tutorial [Läsa in data i R](https://martin-lind.github.io/Introduktion-till-R/tutorials/read-data/#l%C3%A4s-in-filen).

**Glöm inte att dokumentera din kod i ett script,** med kommentarer som förklarar vad du gör! [Se vår tutorial om script](https://martin-lind.github.io/Introduktion-till-R/tutorials/use-R/#anv%C3%A4nda-scriptfiler) om du behöver påminnelse om hur man skapar och använder script.

```{r}
dunlin_data <- read.table("data/dunlin.txt",
                           header=T,
                           sep="\t",
                           dec=",") 
```


### Inspektera data

Börja med att titta på datans struktur med `str()`.

```{r}
str(dunlin_data)
```


```{r}
head(dunlin_data)
```

Det ser ut som om vi har många nollor i datasetet. Låt oss se på ett histogram:

```{r}
hist(dunlin_data$offspring)
```
De flesta honor verkar inte ha fått några ungar. Låt oss se på en QQ-plot som vi även använde i vår tutorial om t-test

```{r}
qqnorm(dunlin_data$offspring)
```
Vi vill att våra värden skall följa en diagonal, men det gör de inte. Vi har ett dataset som inte uppfyller t-testets krav på normalfördelade data, och vi kan inte transformera pg.a. att datasetet mest består av nollvärden som kommer fortsätta att vara nollvärden.


### Visualisera datat med en enkel graf

Vi gör en enkel graf med `boxplot()`

```{r}
boxplot(offspring~treatment, 
        data = dunlin_data)
```

Hur tolkar du grafen? Ser det ut som att antalet avkomma skiljer sig åt beroende på om det är predatorkontroll eller ej?

### Statistisk modellering

Vi vill nu göra ett Wilcoxons test för att undersöka om vår responsvariabel (beroende variabel) *offspring* beror av vår förklarande variabel (oberoende variabel) *treatment*, med andra ord om antalet avkomma beror av huruvida området haft predatorkontroll eller ej

Vi specificerar en modell med hjälp av funktionen `wilcox.test()` och väljer att spara resultatet i ett objekt som vi kallar `m.dunlin`. 

```{r}
m.dunlin<-wilcox.test(offspring~treatment,
                    data=dunlin_data)
```
Vi får en varning `Warning: cannot compute exact p-value with ties`. Det betyder att testet upptäcker att vissa värden är samma (vi har många nollor) och att p-värderna därmed inte går att lita på fullt ut. Det är dock oftast inga problem.

### Statistiska resultat

Vi tittar på resultatet genom att skriva in modellens namn och köra den

```{r}
m.dunlin
```

Vi kan nu inspektera resultatet. Vi får teststatistika (W-värde) samt  ett p-värde. Vi får inga frigetsgrader i det här testet.

Eftersom vårt p-värde är mindre än 0.05 säger vi att antalet avkommor skiljer sig åt beroende på behandling. Stämmer det om du tittar på din boxplot?

### Presentera din statistiska analys

Den sydliga kärrsnäppan fårt fler avkommor om man tillämpar predatorkontroll än i områden utan predatorkontroll (Wilcoxons test, W = 9.5, p = 0.047).

## Kruskal Wallis test

Kruskal Wallis test är en ickeparametrisk ersättning till envägs ANOVA. Det är ett svagare och mindre flexibelt test än en vanlig envägs ANOVA och skall bara användas i nödfall.

Vi vill undersöka om täckningsgraden av blåbär skiljer sig åt i tre skogar. Täckningsgraden har skattats enligt Braun-Blanquet-skalan med fem nivåer (1-5) där täckningsgraden ökar från 1 -> 5. Data är därmed ordnade (1 är lägre än 5) men på ordinalskala (kategorierna är inga mätvärden). 

### Läs in data

Ladda ner följande fil [cover.txt](data/cover.txt) (högerklicka, välj "spara länk som") och spara filen på din hårddisk i en mapp med ett lämpligt namn.

```{r}
cover_data <- read.table("data/cover.txt",
                           header=T,
                           sep="\t",
                           dec=",") 
```

### Inspektera data

Börja med att titta på datans struktur med `str()`.

```{r}
str(cover_data)
```


```{r}
head(cover_data)
```
Låt oss se på ett histogram
```{r}
hist(cover_data$Cover.cathegory)
```
Vi ser att våra data inte ser ut att följa någon normalfördelning, och dessutom vet vi att det är *ordinaldata*, dvs vår responsvariabel är inte mätvärden utan i ordnade kategorier. Bara det senare faktumet gör att vi inte skall använda oss av en vanlig envägs-ANOVA. Icke-normalfördelat data är mindre viktigt, eftersom en envägs ANOVA kräver att det är *residualerna* som skall vara normalfördelade.

### Visualisera datat med en enkel graf

Vi gör en enkel graf med `boxplot()`

```{r}
boxplot(Cover.cathegory~Forest, 
        data = cover_data)
```

Hur tolkar du grafen? Ser det ut som att blåbärens täckningsgrad skiljer sig åt mellan skogarna?

### Statistisk modellering

Vi vill nu göra ett Kruskal Wallis test  för att undersöka om vår responsvariabel (beroende variabel) *Cover.cathegory* beror av vår förklarande variabel (oberoende variabel) *Forest*

Vi specificerar en modell med hjälp av funktionen `kruskal.test()` och väljer att spara resultatet i ett objekt som vi kallar `m.cover`. 


```{r}
m.cover<-kruskal.test(Cover.cathegory~Forest,
                    data=cover_data)
```

```{r}
m.cover
```

### Post-hoc test
Vi har en signifikant efekt av Forest, d.v.s. täckningsgraden för blåbär skiljer sig åt mellan de olika skogarna. Men vilka skogar skiljer sig åt? Vi behöver göra ett post-hoc test! Om vi inte hade haft en signifikant effekt skall vi däremot inte göra ett post-hoc test.

När man gör ett posthoc-test på en icke-parametrisk envägs-ANOVA använder man sig av *Dunnets Test*, vilket finns tillgängligt i paketet **dunn.test**.  Om du inte sedan tidigare har paketet installerat så gör du det med koden `install.packages("dunn.test")`. Innan du använder paketet behöver du läsa in det i din session i R genom funktionen `library()`

När vi läst in paketet använder vi oss av funktionen `dunn.test()`. Först anger vi vår responsvariabel, och det gör vi enligt formeln **`Datatset$Variabel`**, vilket i vårat fall blir `cover_data$Cover.cathegory`. Efter det anger vi vår förklarande faktor på samma sätt, vilket blir `cover_data$Forest`, och slutligen anger vi metoden för att korrigera p-värden för multipla test. Vanligt är att använda sig av *Holm's metod*, anges med `method="holm"`.

```{r}
library(dunn.test)

dunn.test(cover_data$Cover.cathegory,cover_data$Forest,method="holm")
```

Vi får en tabell med jämförelser. Om vi börjar med *Kolumn A* och *Rad B* får vi p-värdet `0.0010.` Det betyder att täckningsgraden för blåbär skiljer sig åt mellan skogarna A och B. 

*Kolumn A* och *rad C* ger ett p-värde på `0.0971.` Täckningsgraden skiljer sig alltså **inte** åt mellan skogarna A och C.

*Kolumn B* och *rad C* ger ett p-värde på `0.0343.` Täckningsgraden av blåbär skiljer sig åt mellan skogarna B och C.

### Presentera din statistiska analys

Täckningsgraden av blåbär skiljer sig åt mellan de olika skogarna (Kruskal Wallis test, $\chi$ ^2^ = 11.883,d.f. = 2, p = 0.003). Pst-hoc analys visar att täckningsgraden är högre i skog B än i skog A (Dunnet's test, p = 0.001) och C (Dunnet's test, p = 0.034). Täckningsgraden skiljer sig inte åt mellan skog A och C (Dunnet's test, p = 0.097).

## Test för normalfördelning

